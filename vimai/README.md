## ask llm questions in vim

Optionally includes context selected in visual line mode.

https://github.com/okuvshynov/experiments/assets/661042/4a135225-4dc0-4d16-8d00-0cdf5f06d6a8

TODO:
1. name?
2. make available somewhere
3. add questions within the code itself.
4. message history
5. local llama.cpp server (w. llama3 or equivalent)

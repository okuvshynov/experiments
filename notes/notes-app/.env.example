# Server Configuration
PORT=3000

# LLM Configuration
LLM_ENDPOINT=http://localhost:1234/v1/chat/completions
LLM_API_KEY=your-api-key-here
LLM_MODEL=gpt-3.5-turbo

# For OpenAI API:
# LLM_ENDPOINT=https://api.openai.com/v1/chat/completions
# LLM_API_KEY=sk-your-openai-key

# For local LLM (like LM Studio):
# LLM_ENDPOINT=http://localhost:1234/v1/chat/completions
# LLM_API_KEY=dummy-key